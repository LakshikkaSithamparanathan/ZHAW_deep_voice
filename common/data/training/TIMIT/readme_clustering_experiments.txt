Speaker clustering experimental setup as used at ZHAW
-------------------------------------------------------

The basic setup is detailed in [1]  and re-used in [2]:
- We use the first n (in lexicographic order of the path name in the directory structure) spakers of the TIMIT test set (folder TEST/) in order to do clustering for n speakers
- Each speaker has 10 sentences (=wav files) in his/her folder; we use the first 8 (again using lexicographic ordering by file name) as the first utterance, and the last 2 as the second utterance per speaker
- Thus, each experiment has 2n utterances, spoken by n speakers
- The system doesn't know n, and doesn't know that there are exactly 2 utterances per speaker
- The system knows which feature vectors belong to which utterance (i.e., that they belong together)
- The system knows the segmentation into utterances
- We usually start experimenting with a small subset of the speakers (e.g., n=10); meaningful results can be reported on n=20 and n=40 speakers (current best missclassification rate for n=40 is MR=0.05 according to [2])
- The speaker subsets for experimentation can be generated by taking the files mentioned in the corpus file "timit-reynolds-clustering-40_RIFF.crp", which gives the full path for all the files needed to concustrct the utterances; all rows where the path stays constant belong to one utterance; the corpus file is constructed such that it first contains (in 8x40 rows) the files constituting utterances 2, and then (in the same order) in 2x40 rows the files of utternace 2 for the same speakers 
- If we (for technical reasons) cannot cluster whole utterances, but only smaller subsets of them, we usually incorporate the system's knowldge of the utterances by averaging (or: majority voting) the cluster assignment for all such sub-segments in an utterance

[1] Stadelmann and Freisleben (2009). "Unfolding Speaker Clustering Potential: A Biomimetic Approach". In Proceedings of the ACM International Conference on Multimedia (ACMMM'09), pages 185-194, Beijing, China, October 2009. ACM. 
[2] Lukic, Vogt, Dürr and Stadelmann (2016). "Speaker Identification and Clustering using Convolutional Neural Networks". In Proceedings of IEEE International Workshop on Machine Learning for Signal Processing (MLSP 2016). Salerno: IEEE.

Thilo Stadelmann, 15.12.2016